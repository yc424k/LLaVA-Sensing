# 2025년 9월 4일 회의록

## 프로젝트: LLaVA-Sensing 데이터 생성 시스템 개발

### 참석자
- 사용자: 프로젝트 관리자
- Claude: AI 개발 어시스턴트

---

## 1. 문제 상황 분석

### 1.1 초기 문제: preprocess_with_args.py 실행 이슈
- **문제**: Simple 모드는 작동하지 않는다고 판단 (후에 numpy 존재 시 advanced 모드 자동 실행으로 오해)
- **실제 상황**: `--mode` 파라미터로 명시적 지정 필요
- **해결**: 모드별 동작 방식 명확화

### 1.2 NLTK 리소스 누락
- **문제**: `punkt_tab` 리소스 없음으로 인한 실행 실패
- **해결**: `nltk.download('punkt_tab')` 실행으로 해결

### 1.3 Division by Zero 에러
- **문제**: `samples_per_category = target_size // len(categories)` 에서 categories 길이가 0
- **원인**: 처리된 예제가 없어서 빈 categories 리스트
- **해결**: 예외 처리 추가로 안전하게 빈 데이터셋 반환

---

## 2. 주요 문제: 감각 키워드 언어 불일치

### 2.1 문제 발견
- **현상**: 모든 텍스트 파일에서 "Generated 0 examples" 출력
- **근본 원인**: 감각 키워드가 한국어인데 처리할 소설은 영어
- **결과**: 감각 점수가 모두 0.0으로 필터링됨

### 2.2 해결 과정
```python
# 한국어 키워드 (문제)
temperature_hot=["뜨거운", "더운", "무더운", ...]

# 영어 키워드로 교체 (해결)
temperature_hot=["hot", "warm", "heated", "burning", ...]
```

### 2.3 영어 키워드 적용 결과
- **온도 (뜨거움)**: "hot", "warm", "sun", "heat" 등
- **온도 (차가움)**: "cold", "cool", "freezing", "snow" 등
- **습도/바람/움직임/감각** 카테고리별 영어 키워드 매핑

---

## 3. AI 기반 감각 분석 구현

### 3.1 요구사항
- 사용자 요청: "키워드 형식이 아니라 AI를 사용하는 방법은 없을까?"
- 목표: 로컬 LLM을 사용한 감정/감각 분류

### 3.2 구현한 3가지 LLM 백엔드

#### A. Ollama 백엔드
```python
# 로컬 Llama 모델 사용
model: "llama3.2:3b"
# 직접적인 감각 점수 분석 프롬프트
```

#### B. Transformers 백엔드 (채택)
```python
# Hugging Face 모델
model: "cardiffnlp/twitter-roberta-base-sentiment-latest"
# GPU 지원: CUDA 자동 감지
# 감정 → 감각 매핑
```

#### C. llama-cpp-python 백엔드
```python
# 최적화된 로컬 추론
# GGUF 모델 파일 필요
```

### 3.3 AI 휴리스틱 강화
- **날씨 패턴**: "the weather", "storm", "climate" (3점)
- **신체 감각**: "felt", "shiver", "comfortable" (2점)
- **환경 묘사**: "atmosphere", "surroundings" (2점)
- **신체 반응**: "shivered", "coat", "jacket" (2점)

---

## 4. 기술적 도전과 해결

### 4.1 Bus Error 문제
- **문제**: `[1] 629730 bus error (core dumped)` 발생
- **원인**: 대용량 LLM 모델 로딩 시 메모리 부족
- **해결 시도**:
  1. CPU 전용 모드 강제: `CUDA_VISIBLE_DEVICES=""`
  2. LLM 비활성화 테스트
  3. 더 가벼운 모델 선택

### 4.2 GPU 최적화 구현
```python
# GPU 자동 감지
device = "cuda" if torch.cuda.is_available() else "cpu"

# 메모리 최적화
torch_dtype=torch.float16 if device == "cuda" else torch.float32
low_cpu_mem_usage=True
use_cache=False
```

### 4.3 임계값 조정
- **초기**: `sensory_score < 0.2`, `confidence < 0.3`
- **조정**: `sensory_score < 0.05`, `confidence < 0.1`
- **최종**: `min_confidence=0.1` (preprocess_with_args.py)

---

## 5. 성공적인 테스트 결과

### 5.1 테스트 성과 (LLM 비활성화)
```
Total generated examples: 60
- Modernist: 14개
- Travel: 46개

데이터셋 분할:
- Train: 48 examples
- Validation: 6 examples  
- Test: 6 examples
```

### 5.2 감각 분석 향상
- **키워드 매칭**: 단어 경계 검사로 정확도 향상
- **변형 형태**: `-s`, `-ed`, `-ing` 지원
- **AI 휴리스틱**: 문맥적 감각 표현 포착

---

## 6. 최종 구현 사양

### 6.1 LLM 백엔드 (Transformers)
- **모델**: `cardiffnlp/twitter-roberta-base-sentiment-latest`
- **감정 분류**: negative, neutral, positive
- **감정→감각 매핑**:
  - positive → general_sensory(4), temperature_hot(2)
  - negative → general_sensory(3), temperature_cold(2), movement(1)
- **GPU 지원**: CUDA 자동 감지 및 최적화

### 6.2 문맥 인식 강화
```python
# 날씨/환경 문맥
if 'weather' in text_lower:
    sensory_scores['general_sensory'] += 1

# 신체 감각 문맥    
if 'feel' in text_lower:
    sensory_scores['general_sensory'] += 1.5

# 움직임 문맥
if 'move' in text_lower:
    sensory_scores['movement'] += 1
```

---

## 7. 향후 계획

### 7.1 즉시 실행 가능
```bash
# LLM 없이 안정적 실행
python3 preprocess_with_args.py --mode advanced --max_files 5 --verbose

# LLM 포함 (시스템 안정화 후)
# GPU 사용 Hugging Face 모델로 감각 분류
```

### 7.2 확장 계획
1. **데이터 규모**: 1파일 → 5파일 → 202파일 순차 확장
2. **모델 최적화**: Bus error 해결 후 더 정교한 감정 모델 적용
3. **성능 향상**: 배치 처리 및 GPU 메모리 관리 최적화

---

## 8. 주요 성과

### 8.1 기술적 성과
- ✅ 한국어→영어 키워드 변환으로 감각 인식률 대폭 향상
- ✅ 3가지 LLM 백엔드 구현 (Ollama, Transformers, llama-cpp)
- ✅ GPU 지원 및 메모리 최적화
- ✅ Division by zero 등 예외 처리 강화
- ✅ 감정→감각 매핑 시스템 구축

### 8.2 데이터 생성 성과
- ✅ 60개 고품질 예제 생성 (1파일 테스트)
- ✅ Train/Val/Test 자동 분할
- ✅ 센서 데이터 매핑 (온도, 습도, IMU, 바람)
- ✅ 메타데이터 포함한 완전한 데이터셋

---

## 9. 기술 스택 정리

### 9.1 개발 환경
- **Python**: 3.x
- **GPU**: NVIDIA GeForce RTX 3080 (10GB VRAM)
- **CUDA**: 12.7

### 9.2 주요 라이브러리
- **transformers**: Hugging Face 모델 로딩
- **torch**: GPU 추론 및 텐서 연산
- **nltk**: 텍스트 토큰화
- **numpy/pandas**: 데이터 처리
- **requests**: Ollama API 통신

### 9.3 모델 목록
- **Primary**: `cardiffnlp/twitter-roberta-base-sentiment-latest`
- **Alternative**: `j-hartmann/emotion-english-distilroberta-base`
- **Ollama**: `llama3.2:3b`

---

## 회의 결론

1. **핵심 문제 해결**: 언어 불일치 문제로 감각 키워드를 한국어→영어 변환
2. **AI 시스템 구축**: GPU 지원 Hugging Face 모델로 감정 기반 감각 분석
3. **안정성 확보**: 예외 처리 및 메모리 최적화로 시스템 안정화
4. **확장성 준비**: 소규모 테스트 성공 후 대규모 데이터 처리 준비 완료

**다음 단계**: 시스템 재시작 후 GPU LLM 백엔드로 대용량 데이터 처리 진행